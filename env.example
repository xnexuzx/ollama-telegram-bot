# Ollama Telegram Bot - Environment Configuration
# Copy this file to .env and fill in your values

# ===========================================
# TELEGRAM BOT CONFIGURATION
# ===========================================

# Your Telegram Bot Token from @BotFather
# Get it here: https://core.telegram.org/bots/tutorial#obtain-your-bot-token
TOKEN=your_telegram_bot_token_here

# Telegram User IDs of ADMINS (can change models and control the bot)
# Find your ID using @userinfobot on Telegram
# Multiple IDs separated by commas (no spaces)
ADMIN_IDS=123456789

# Allow all users in group chats to interact with the bot
# 0 = disabled (only USER_IDS can interact)
# 1 = enabled (anyone in group can interact when bot is mentioned)
ALLOW_ALL_USERS_IN_GROUPS=0

# ===========================================
# OLLAMA CONFIGURATION
# ===========================================

# Ollama API Base URL
# For local installation: localhost
# For Docker on Windows/Mac: host.docker.internal
OLLAMA_BASE_URL=localhost

# Ollama API Port (default: 11434)
OLLAMA_PORT=11434

# Default LLM model to use on startup
# Examples: qwen3:4b-instruct, mistral:latest, llama3:8b, codellama:7b
INITMODEL=qwen3:4b-instruct

# Timeout for generating responses (in seconds)
# Increase for larger models or slower systems
TIMEOUT=3000

# ===========================================
# LOGGING CONFIGURATION
# ===========================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

